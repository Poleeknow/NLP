{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_PATH = Path('public_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(DATASET_PATH / 'train.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ners</th>\n",
       "      <th>sentences</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 5, CITY], [16, 23, PERSON], [34, 41, PERS...</td>\n",
       "      <td>Бостон взорвали Тамерлан и Джохар Царнаевы из ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[21, 28, PROFESSION], [53, 67, ORGANIZATION],...</td>\n",
       "      <td>Умер избитый до комы гитарист и сооснователь г...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0, 4, PERSON], [37, 42, COUNTRY], [47, 76, O...</td>\n",
       "      <td>Путин подписал распоряжение о выходе России из...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 11, PERSON], [36, 47, PROFESSION], [49, 6...</td>\n",
       "      <td>Бенедикт XVI носил кардиостимулятор\\nПапа Римс...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 4, PERSON], [17, 29, ORGANIZATION], [48, ...</td>\n",
       "      <td>Обама назначит в Верховный суд латиноамериканк...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ners  \\\n",
       "0  [[0, 5, CITY], [16, 23, PERSON], [34, 41, PERS...   \n",
       "1  [[21, 28, PROFESSION], [53, 67, ORGANIZATION],...   \n",
       "2  [[0, 4, PERSON], [37, 42, COUNTRY], [47, 76, O...   \n",
       "3  [[0, 11, PERSON], [36, 47, PROFESSION], [49, 6...   \n",
       "4  [[0, 4, PERSON], [17, 29, ORGANIZATION], [48, ...   \n",
       "\n",
       "                                           sentences  id  \n",
       "0  Бостон взорвали Тамерлан и Джохар Царнаевы из ...   0  \n",
       "1  Умер избитый до комы гитарист и сооснователь г...   1  \n",
       "2  Путин подписал распоряжение о выходе России из...   2  \n",
       "3  Бенедикт XVI носил кардиостимулятор\\nПапа Римс...   3  \n",
       "4  Обама назначит в Верховный суд латиноамериканк...   4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels = set(train.ners.apply(lambda x: [y[2] for y in x]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model to predict continuous labels, I splitted labels into two groups. One starts with `B-` and denote a first token within an entity. Other starts with `I-` and denote a token in the middle of the entity. Using this strategy, I will be able to build a token classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_labels = {\n",
    "    'B-' + x for x in full_labels\n",
    "}.union({'I-' + x for x in full_labels})\n",
    "\n",
    "label2id = {\n",
    "    v: k\n",
    "    for k, v in enumerate(splitted_labels)\n",
    "}\n",
    "\n",
    "id2label = {\n",
    "    k: v\n",
    "    for k, v in enumerate(splitted_labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Tokenization is performed with a usual Treebank tokenizer from NLTK package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ner(ner, spans):\n",
    "    x = 0\n",
    "    while x + 1 < len(spans) and spans[x + 1][0] <= ner[0]:\n",
    "        x += 1\n",
    "    ls = x\n",
    "    \n",
    "    x = len(spans) - 1\n",
    "    while x - 1 >= 0 and spans[x - 1][1] >= ner[1]:\n",
    "        x -= 1\n",
    "\n",
    "    rp = x\n",
    "    \n",
    "    return ls, rp\n",
    "\n",
    "def get_labels(row):\n",
    "    \"\"\"Converts (TAG, BEGIN, END) to label vectors for each token\"\"\"\n",
    "    ners, spans = row.ners, row.spans\n",
    "    labels = [[0 for _ in splitted_labels] for _ in spans]\n",
    "    for _, n in enumerate(ners):\n",
    "        i, j = build_ner(n, spans)\n",
    "        labels[i][label2id['B-' + n[2]]] = 1        # first token is B-\n",
    "        \n",
    "        for k in range(i + 1, j + 1):               # rest are I-\n",
    "            labels[k][label2id['I-' + n[2]]] = 1\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ners</th>\n",
       "      <th>sentences</th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 5, CITY], [16, 23, PERSON], [34, 41, PERS...</td>\n",
       "      <td>Бостон взорвали Тамерлан и Джохар Царнаевы из ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(Бостон, 0, 5), (взорвали, 7, 14), (Тамерлан,...</td>\n",
       "      <td>[(0, 5), (7, 14), (16, 23), (25, 25), (27, 32)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[21, 28, PROFESSION], [53, 67, ORGANIZATION],...</td>\n",
       "      <td>Умер избитый до комы гитарист и сооснователь г...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Умер, 0, 3), (избитый, 5, 11), (до, 13, 14),...</td>\n",
       "      <td>[(0, 3), (5, 11), (13, 14), (16, 19), (21, 28)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0, 4, PERSON], [37, 42, COUNTRY], [47, 76, O...</td>\n",
       "      <td>Путин подписал распоряжение о выходе России из...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(Путин, 0, 4), (подписал, 6, 13), (распоряжен...</td>\n",
       "      <td>[(0, 4), (6, 13), (15, 26), (28, 28), (30, 35)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 11, PERSON], [36, 47, PROFESSION], [49, 6...</td>\n",
       "      <td>Бенедикт XVI носил кардиостимулятор\\nПапа Римс...</td>\n",
       "      <td>3</td>\n",
       "      <td>[(Бенедикт, 0, 7), (XVI, 9, 11), (носил, 13, 1...</td>\n",
       "      <td>[(0, 7), (9, 11), (13, 17), (19, 34), (36, 39)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 4, PERSON], [17, 29, ORGANIZATION], [48, ...</td>\n",
       "      <td>Обама назначит в Верховный суд латиноамериканк...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(Обама, 0, 4), (назначит, 6, 13), (в, 15, 15)...</td>\n",
       "      <td>[(0, 4), (6, 13), (15, 15), (17, 25), (27, 29)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>[[42, 46, COUNTRY], [82, 87, COUNTRY], [104, 1...</td>\n",
       "      <td>Глава Малайзии: мы не хотим противостоять Кита...</td>\n",
       "      <td>514</td>\n",
       "      <td>[(Глава, 0, 4), (Малайзии, 6, 13), (:, 14, 14)...</td>\n",
       "      <td>[(0, 4), (6, 13), (14, 14), (16, 17), (19, 20)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>[[1, 4, PRODUCT], [31, 33, FACILITY], [35, 44,...</td>\n",
       "      <td>\"Союз\" впервые пристыковался к МКС за 6 часов\\...</td>\n",
       "      <td>515</td>\n",
       "      <td>[(``, 0, 0), (Союз, 1, 4), ('', 5, 5), (впервы...</td>\n",
       "      <td>[(0, 0), (1, 4), (5, 5), (7, 13), (15, 27), (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>[[0, 4, PERSON], [8, 12, PERSON], [45, 52, AGE...</td>\n",
       "      <td>Трамп и Путин сделали совместное заявление к 7...</td>\n",
       "      <td>516</td>\n",
       "      <td>[(Трамп, 0, 4), (и, 6, 6), (Путин, 8, 12), (сд...</td>\n",
       "      <td>[(0, 4), (6, 6), (8, 12), (14, 20), (22, 31), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>[[0, 9, NATIONALITY], [58, 72, PERSON], [101, ...</td>\n",
       "      <td>Российский магнат устроил самую дорогую свадьб...</td>\n",
       "      <td>517</td>\n",
       "      <td>[(Российский, 0, 9), (магнат, 11, 16), (устрои...</td>\n",
       "      <td>[(0, 9), (11, 16), (18, 24), (26, 30), (32, 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[[0, 4, PERSON], [16, 25, PROFESSION], [27, 38...</td>\n",
       "      <td>Трамп поздравил астронавта Пегги Уитсон с уста...</td>\n",
       "      <td>518</td>\n",
       "      <td>[(Трамп, 0, 4), (поздравил, 6, 14), (астронавт...</td>\n",
       "      <td>[(0, 4), (6, 14), (16, 25), (27, 31), (33, 38)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ners  \\\n",
       "0    [[0, 5, CITY], [16, 23, PERSON], [34, 41, PERS...   \n",
       "1    [[21, 28, PROFESSION], [53, 67, ORGANIZATION],...   \n",
       "2    [[0, 4, PERSON], [37, 42, COUNTRY], [47, 76, O...   \n",
       "3    [[0, 11, PERSON], [36, 47, PROFESSION], [49, 6...   \n",
       "4    [[0, 4, PERSON], [17, 29, ORGANIZATION], [48, ...   \n",
       "..                                                 ...   \n",
       "514  [[42, 46, COUNTRY], [82, 87, COUNTRY], [104, 1...   \n",
       "515  [[1, 4, PRODUCT], [31, 33, FACILITY], [35, 44,...   \n",
       "516  [[0, 4, PERSON], [8, 12, PERSON], [45, 52, AGE...   \n",
       "517  [[0, 9, NATIONALITY], [58, 72, PERSON], [101, ...   \n",
       "518  [[0, 4, PERSON], [16, 25, PROFESSION], [27, 38...   \n",
       "\n",
       "                                             sentences   id  \\\n",
       "0    Бостон взорвали Тамерлан и Джохар Царнаевы из ...    0   \n",
       "1    Умер избитый до комы гитарист и сооснователь г...    1   \n",
       "2    Путин подписал распоряжение о выходе России из...    2   \n",
       "3    Бенедикт XVI носил кардиостимулятор\\nПапа Римс...    3   \n",
       "4    Обама назначит в Верховный суд латиноамериканк...    4   \n",
       "..                                                 ...  ...   \n",
       "514  Глава Малайзии: мы не хотим противостоять Кита...  514   \n",
       "515  \"Союз\" впервые пристыковался к МКС за 6 часов\\...  515   \n",
       "516  Трамп и Путин сделали совместное заявление к 7...  516   \n",
       "517  Российский магнат устроил самую дорогую свадьб...  517   \n",
       "518  Трамп поздравил астронавта Пегги Уитсон с уста...  518   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [(Бостон, 0, 5), (взорвали, 7, 14), (Тамерлан,...   \n",
       "1    [(Умер, 0, 3), (избитый, 5, 11), (до, 13, 14),...   \n",
       "2    [(Путин, 0, 4), (подписал, 6, 13), (распоряжен...   \n",
       "3    [(Бенедикт, 0, 7), (XVI, 9, 11), (носил, 13, 1...   \n",
       "4    [(Обама, 0, 4), (назначит, 6, 13), (в, 15, 15)...   \n",
       "..                                                 ...   \n",
       "514  [(Глава, 0, 4), (Малайзии, 6, 13), (:, 14, 14)...   \n",
       "515  [(``, 0, 0), (Союз, 1, 4), ('', 5, 5), (впервы...   \n",
       "516  [(Трамп, 0, 4), (и, 6, 6), (Путин, 8, 12), (сд...   \n",
       "517  [(Российский, 0, 9), (магнат, 11, 16), (устрои...   \n",
       "518  [(Трамп, 0, 4), (поздравил, 6, 14), (астронавт...   \n",
       "\n",
       "                                                 spans  \n",
       "0    [(0, 5), (7, 14), (16, 23), (25, 25), (27, 32)...  \n",
       "1    [(0, 3), (5, 11), (13, 14), (16, 19), (21, 28)...  \n",
       "2    [(0, 4), (6, 13), (15, 26), (28, 28), (30, 35)...  \n",
       "3    [(0, 7), (9, 11), (13, 17), (19, 34), (36, 39)...  \n",
       "4    [(0, 4), (6, 13), (15, 15), (17, 25), (27, 29)...  \n",
       "..                                                 ...  \n",
       "514  [(0, 4), (6, 13), (14, 14), (16, 17), (19, 20)...  \n",
       "515  [(0, 0), (1, 4), (5, 5), (7, 13), (15, 27), (2...  \n",
       "516  [(0, 4), (6, 6), (8, 12), (14, 20), (22, 31), ...  \n",
       "517  [(0, 9), (11, 16), (18, 24), (26, 30), (32, 38...  \n",
       "518  [(0, 4), (6, 14), (16, 25), (27, 31), (33, 38)...  \n",
       "\n",
       "[519 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentences'] = train.sentences.apply(lambda x: x.replace('«', '\\\"').replace('»', '\\\"'))\n",
    "train['tokens'] = train.sentences.apply(lambda s: [(y, x[0], x[1] - 1) for y, x in zip(tokenizer.tokenize(s), tokenizer.span_tokenize(s))])\n",
    "train['spans'] =  train.sentences.apply(lambda s: [(x, y - 1) for x, y in tokenizer.span_tokenize(s)])\n",
    "train['labels'] = train.apply(get_labels, axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135505, 135505)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = train.copy()\n",
    "t.tokens = t.tokens.apply(lambda x: [y[0] for y in x])\n",
    "t = t[['tokens', 'labels']]\n",
    "\n",
    "all_tokens = t.tokens.sum()\n",
    "full_labels = t.labels.sum()\n",
    "\n",
    "len(all_tokens), len(full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135473, 135473)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW = 32 # A number of words per one model run\n",
    "\n",
    "sequences, labels = [], []\n",
    "\n",
    "for t in range(len(all_tokens) - WINDOW):\n",
    "    sequences.append(all_tokens[t:t+WINDOW])\n",
    "    labels.append(full_labels[t:t+WINDOW])\n",
    "    \n",
    "len(sequences), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "Pair = tuple[int, int]\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_tokens: list[list[tuple[int, int, str]]],\n",
    "        batch_labels: list[list[int]],\n",
    "    ):\n",
    "        self._tokens = sum(batch_tokens, [])\n",
    "        self._ners = sum(batch_labels, [])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._tokens)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._tokens[index], self._ners[index]\n",
    "    \n",
    "\n",
    "def vectorize(word: str) -> torch.Tensor:\n",
    "    if word not in embeddings:\n",
    "        # If not found, return sum of embeddings of all characters\n",
    "        vec = torch.stack([\n",
    "            torch.as_tensor(embeddings.get(x, embeddings['<unk>']))\n",
    "            for x in word\n",
    "        ], dim=0).mean(dim=0)\n",
    "    else:\n",
    "        vec = embeddings.get(word)\n",
    "    return torch.as_tensor(vec)\n",
    "        \n",
    "class NERLoader(DataLoader):\n",
    "\n",
    "    def __init__(self, dataset: NERDataset, *args, **kwargs):\n",
    "        if not isinstance(dataset, NERDataset):\n",
    "            raise ValueError('NERLoader only supports NERDataset')\n",
    "        \n",
    "        def collate(batch):\n",
    "            tokens, ners = zip(*batch)\n",
    "            inputs = torch.stack([\n",
    "                vectorize(x[0])\n",
    "                for x in tokens\n",
    "            ])\n",
    "\n",
    "            # (batch, tokens)\n",
    "            # (batch, cls)\n",
    "            return inputs, torch.tensor(ners, dtype=torch.long)\n",
    "        \n",
    "        super().__init__(dataset, *args, **kwargs, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(train.tokens.to_list(), train.labels.to_list())\n",
    "train_loader = NERLoader(train_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(300, 512, 16, batch_first=True)\n",
    "        self.class_head = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 58)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_sequence: torch.Tensor):\n",
    "        output, _ = self.gru(input_sequence)\n",
    "        return self.class_head(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "for spans, labels in train_loader:\n",
    "    spans = spans.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(spans)\n",
    "    \n",
    "    loss = crit(outputs, labels.to(torch.float))\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Бостон, взорвали, Тамерлан, и, Джохар, Царнае...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[взорвали, Тамерлан, и, Джохар, Царнаевы, из, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Тамерлан, и, Джохар, Царнаевы, из, Северного,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[и, Джохар, Царнаевы, из, Северного, Кавказа, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Джохар, Царнаевы, из, Северного, Кавказа, 19,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Бостон, взорвали, Тамерлан, и, Джохар, Царнае...   \n",
       "1  [взорвали, Тамерлан, и, Джохар, Царнаевы, из, ...   \n",
       "2  [Тамерлан, и, Джохар, Царнаевы, из, Северного,...   \n",
       "3  [и, Джохар, Царнаевы, из, Северного, Кавказа, ...   \n",
       "4  [Джохар, Царнаевы, из, Северного, Кавказа, 19,...   \n",
       "\n",
       "                                               label  \n",
       "0  [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2  [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched = pd.DataFrame([*zip(sequences, labels)], columns=['tokens', 'label'])\n",
    "batched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121926, 13547, 519)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = batched.sample(frac=0.9)\n",
    "val_split = batched[~batched.index.isin(train_split.index)]\n",
    "\n",
    "len(train_split), len(val_split), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_label = train_split.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_split.reset_index(drop=True)),\n",
    "    'val': Dataset.from_pandas(val_split.reset_index(drop=True))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertModel, BertConfig\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertForNER(BertModel):\n",
    "    def __init__(self, config: BertConfig):\n",
    "        super().__init__(config)\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Linear(config.hidden_size, config.hidden_size),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(.2),\n",
    "            )] * 6,\n",
    "            nn.Linear(config.hidden_size, 58)\n",
    "        )\n",
    "        self.__pos_weight = torch.full((1, 1, 58), 5)\n",
    "        \n",
    "    def forward(self, return_loss = True, **kwargs):\n",
    "        labels = kwargs.pop('labels', None)\n",
    "        kwargs.pop('output_hidden_states', None)\n",
    "        \n",
    "        output = super().forward(**kwargs, return_dict=True, output_hidden_states=True)\n",
    "        preds = self.classifier_head(output.hidden_states[-1])\n",
    "        \n",
    "        output['predictions'] = preds\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                preds,\n",
    "                labels,\n",
    "                pos_weight=self.__pos_weight.to(preds.device)\n",
    "            )     \n",
    "        else:\n",
    "            loss = None       \n",
    "    \n",
    "        return loss, output if labels is not None and return_loss else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForNER were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['bert.classifier_head.0.0.bias', 'bert.classifier_head.0.0.weight', 'bert.classifier_head.1.0.bias', 'bert.classifier_head.1.0.weight', 'bert.classifier_head.2.0.bias', 'bert.classifier_head.2.0.weight', 'bert.classifier_head.3.0.bias', 'bert.classifier_head.3.0.weight', 'bert.classifier_head.4.0.bias', 'bert.classifier_head.4.0.weight', 'bert.classifier_head.5.0.bias', 'bert.classifier_head.5.0.weight', 'bert.classifier_head.6.bias', 'bert.classifier_head.6.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForNER.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataset(batch):\n",
    "    tokens = [bert_tokenizer.convert_tokens_to_ids(x) for x in batch['tokens']]\n",
    "        \n",
    "    input_ids = torch.tensor(tokens, dtype=torch.long)\n",
    "    labels = torch.tensor(batch['label'], dtype=torch.float32)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.map(prepare_dataset, batched=True, batch_size=256).remove_columns('tokens').save_to_disk('./dataset/tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import DatasetDict\n",
    "\n",
    "# ds = DatasetDict.load_from_disk('./dataset/tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='./bert',\n",
    "    per_device_eval_batch_size=700,\n",
    "    per_device_train_batch_size=700,\n",
    "    num_train_epochs=15,\n",
    "    run_name='bert-ner-class',\n",
    "    evaluation_strategy='steps',\n",
    "    logging_steps=25,\n",
    "    save_steps=1000,\n",
    "    eval_steps=150,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['val'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='885' max='885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [885/885 52:42, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.100966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.092055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.083609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.067447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.058260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=885, training_loss=0.10720483192616263, metrics={'train_runtime': 3170.7864, 'train_samples_per_second': 576.794, 'train_steps_per_second': 0.279, 'total_flos': 3.029757995472768e+16, 'train_loss': 0.10720483192616263, 'epoch': 15.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /shared/nlp/bert/checkpoint-400 were not used when initializing BertForNER: ['classifier_head.bias', 'classifier_head.weight']\n",
      "- This IS expected if you are initializing BertForNER from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNER from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForNER were not initialized from the model checkpoint at /shared/nlp/bert/checkpoint-400 and are newly initialized: ['classifier_head.0.0.bias', 'classifier_head.0.0.weight', 'classifier_head.1.0.bias', 'classifier_head.1.0.weight', 'classifier_head.2.0.bias', 'classifier_head.2.0.weight', 'classifier_head.3.0.bias', 'classifier_head.3.0.weight', 'classifier_head.4.0.bias', 'classifier_head.4.0.weight', 'classifier_head.5.0.bias', 'classifier_head.5.0.weight', 'classifier_head.6.bias', 'classifier_head.6.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForNER.from_pretrained('/shared/nlp/bert/checkpoint-400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/13547 [00:00<11:41, 19.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 120/13547 [00:12<23:34,  9.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredictions\n\u001b[1;32m     12\u001b[0m tags \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msigmoid(outputs)\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m.5\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     13\u001b[0m tp \u001b[38;5;241m=\u001b[39m ((labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (tags \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m, in \u001b[0;36mBertForNER.forward\u001b[0;34m(self, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m labels \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier_head(output\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     24\u001b[0m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:308\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    306\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m1\u001b[39m], value_layer], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    309\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(hidden_states))\n\u001b[1;32m    311\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "accuracy, recall, precision, n = 0, 0, 0, 0\n",
    "for batch in tqdm(ds['val']):\n",
    "    tokens = torch.tensor(batch['input_ids'], dtype=torch.long, device=device).unsqueeze(0)\n",
    "    labels = torch.tensor(batch['labels'], dtype=torch.long, device=device).unsqueeze(0)\n",
    "    outputs = model(input_ids=tokens)[1].predictions\n",
    "\n",
    "    \n",
    "    tags = (torch.nn.functional.sigmoid(outputs).squeeze() > .5).to(torch.long)\n",
    "    tp = ((labels == 1) & (tags == 1)).sum()\n",
    "    tn = ((labels == 0) & (tags == 0)).sum()\n",
    "    fp = ((labels == 0) & (tags == 1)).sum()\n",
    "    fn = ((labels == 1) & (tags == 0)).sum()\n",
    "    precision += tp / max(1, (tp + fp))\n",
    "    recall += tp / max(1, (tp + fn))\n",
    "    accuracy += (tp + tn) / labels.numel()\n",
    "    n += 1\n",
    "    \n",
    "accuracy / n, precision / n, recall / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def convert_to_submit(labels: list[torch.Tensor], spans: list[tuple[int, int]]):\n",
    "    # labels of shape (sequence_length, num_classes), binary tensor (0 or 1)\n",
    "    # spans are pairs (begin, end)\n",
    "    assert len(labels) == len(spans), (len(labels), len(spans))\n",
    "    \n",
    "    start_label_ids = {v for k, v in label2id.items() if k.startswith('B-')}\n",
    "    # segment_label_ids = {v for k, v in label2id if k.startswith('I-')}\n",
    "    \n",
    "    ners = []\n",
    "    current_ners = []\n",
    "    for i, label in enumerate(labels):\n",
    "        index = torch.arange(58)\n",
    "        predicted = index[label.cpu() == 1].tolist()\n",
    "        expanded = [False] * len(current_ners)\n",
    "        new_ners = []\n",
    "        for p in predicted:\n",
    "            if p not in start_label_ids:\n",
    "                for j, c in enumerate(current_ners):\n",
    "                    if c[0] == id2label[p][2:]:\n",
    "                        # expanding\n",
    "                        c[2] = spans[i][1]\n",
    "                        expanded[j] = True\n",
    "            else:\n",
    "                new_ners.append([id2label[p][2:], *spans[i]])\n",
    "        \n",
    "        ners.extend([c for j, c in enumerate(current_ners) if not expanded[j]])\n",
    "        current_ners = [c for j, c in enumerate(current_ners) if expanded[j]]\n",
    "        current_ners += new_ners\n",
    "        \n",
    "    return ners\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Бостон взорвали Тамерлан и Джохар Царнаевы из Северного Кавказа\\n\\n19 апреля 2013 года в пригороде Бостона  проходит спецоперация по поимке 19-летнего Джохара Царнаева, подозреваемого в теракте на Бостонском марафоне 15 апреля и в смертельном ранении полицей',\n",
       " ['Бостон',\n",
       "  'взорвали',\n",
       "  'Тамерлан',\n",
       "  'и',\n",
       "  'Джохар',\n",
       "  'Царнаевы',\n",
       "  'из',\n",
       "  'Северного',\n",
       "  'Кавказа',\n",
       "  '19',\n",
       "  'апреля',\n",
       "  '2013',\n",
       "  'года',\n",
       "  'в',\n",
       "  'пригороде',\n",
       "  'Бостона',\n",
       "  'проходит',\n",
       "  'спецоперация',\n",
       "  'по',\n",
       "  'поимке',\n",
       "  '19',\n",
       "  '-',\n",
       "  'летнего',\n",
       "  'Джохара',\n",
       "  'Царнаева',\n",
       "  ',',\n",
       "  'подозреваемого',\n",
       "  'в',\n",
       "  'теракте',\n",
       "  'на',\n",
       "  'Бостонском',\n",
       "  'марафоне',\n",
       "  '15',\n",
       "  'апреля',\n",
       "  'и',\n",
       "  'в',\n",
       "  'смертельном',\n",
       "  'ранении',\n",
       "  'полицей'],\n",
       " [(0, 6),\n",
       "  (7, 15),\n",
       "  (16, 24),\n",
       "  (25, 26),\n",
       "  (27, 33),\n",
       "  (34, 42),\n",
       "  (43, 45),\n",
       "  (46, 55),\n",
       "  (56, 63),\n",
       "  (65, 67),\n",
       "  (68, 74),\n",
       "  (75, 79),\n",
       "  (80, 84),\n",
       "  (85, 86),\n",
       "  (87, 96),\n",
       "  (97, 104),\n",
       "  (106, 114),\n",
       "  (115, 127),\n",
       "  (128, 130),\n",
       "  (131, 137),\n",
       "  (138, 140),\n",
       "  (140, 141),\n",
       "  (141, 148),\n",
       "  (149, 156),\n",
       "  (157, 165),\n",
       "  (165, 166),\n",
       "  (167, 181),\n",
       "  (182, 183),\n",
       "  (184, 191),\n",
       "  (192, 194),\n",
       "  (195, 205),\n",
       "  (206, 214),\n",
       "  (215, 217),\n",
       "  (218, 224),\n",
       "  (225, 226),\n",
       "  (227, 228),\n",
       "  (229, 240),\n",
       "  (241, 248),\n",
       "  (249, 256)],\n",
       " [37104,\n",
       "  65193,\n",
       "  82820,\n",
       "  851,\n",
       "  100,\n",
       "  100,\n",
       "  1703,\n",
       "  19939,\n",
       "  27083,\n",
       "  1653,\n",
       "  6167,\n",
       "  7262,\n",
       "  1768,\n",
       "  845,\n",
       "  30319,\n",
       "  58359,\n",
       "  12455,\n",
       "  90484,\n",
       "  1516,\n",
       "  68780,\n",
       "  1653,\n",
       "  130,\n",
       "  17365,\n",
       "  100,\n",
       "  100,\n",
       "  128,\n",
       "  33503,\n",
       "  845,\n",
       "  61965,\n",
       "  1469,\n",
       "  100,\n",
       "  61263,\n",
       "  3996,\n",
       "  6167,\n",
       "  851,\n",
       "  845,\n",
       "  100,\n",
       "  100,\n",
       "  12707])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train.sentences.iloc[0][:256]\n",
    "tokens = tokenizer.tokenize(text)\n",
    "spans = [*tokenizer.span_tokenize(text)]\n",
    "bert_tokens = list(map(bert_tokenizer.convert_tokens_to_ids, tokens))\n",
    "\n",
    "text, tokens, spans, bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 39, 58])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(input_ids=torch.tensor(bert_tokens, dtype=torch.long, device=device).unsqueeze(0))[1].predictions\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.5447e-01, 4.2160e-01, 1.0310e-02,  ..., 6.9357e-02,\n",
       "          1.1827e-02, 1.3931e-01],\n",
       "         [6.2095e-02, 2.4527e-02, 9.8676e-04,  ..., 3.5091e-03,\n",
       "          6.2504e-04, 3.8328e-01],\n",
       "         [3.1347e-02, 8.7105e-02, 6.0223e-02,  ..., 1.7785e-01,\n",
       "          9.8626e-02, 1.1556e-01],\n",
       "         ...,\n",
       "         [2.9908e-01, 2.2549e-01, 1.5095e-02,  ..., 5.4263e-02,\n",
       "          1.6378e-02, 1.6989e-01],\n",
       "         [7.8707e-02, 1.6943e-01, 6.8879e-02,  ..., 1.2658e-01,\n",
       "          6.1039e-02, 4.2061e-01],\n",
       "         [2.6907e-04, 9.4651e-04, 2.0710e-04,  ..., 7.1986e-03,\n",
       "          1.2778e-03, 2.5372e-02]]], device='cuda:1',\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 39, 58])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = (torch.nn.functional.sigmoid(outputs) > 0.5).to(torch.long)\n",
    "tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9, device='cuda:1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tags == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = convert_to_submit(tags.squeeze(), spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([(x[0], text[x[1]:x[2]]) for x in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senences</th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Владелец \"Бирмингема\" получил шесть лет тюрьмы...</td>\n",
       "      <td>584</td>\n",
       "      <td>[(Владелец, 0, 7), (``, 9, 9), (Бирмингема, 10...</td>\n",
       "      <td>[(0, 7), (9, 9), (10, 19), (20, 20), (22, 28),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Акция протеста на Майдане Независимости объявл...</td>\n",
       "      <td>585</td>\n",
       "      <td>[(Акция, 0, 4), (протеста, 6, 13), (на, 15, 16...</td>\n",
       "      <td>[(0, 4), (6, 13), (15, 16), (18, 24), (26, 38)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Фольксваген может перейти под контроль Порше \\...</td>\n",
       "      <td>586</td>\n",
       "      <td>[(Фольксваген, 0, 10), (может, 12, 16), (перей...</td>\n",
       "      <td>[(0, 10), (12, 16), (18, 24), (26, 28), (30, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Москве покажут фильмы Чарли Чаплина с живой ...</td>\n",
       "      <td>587</td>\n",
       "      <td>[(В, 0, 0), (Москве, 2, 7), (покажут, 9, 15), ...</td>\n",
       "      <td>[(0, 0), (2, 7), (9, 15), (17, 22), (24, 28), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Чулпан Хаматова сыграет главную роль в фильме ...</td>\n",
       "      <td>588</td>\n",
       "      <td>[(Чулпан, 0, 5), (Хаматова, 7, 14), (сыграет, ...</td>\n",
       "      <td>[(0, 5), (7, 14), (16, 22), (24, 30), (32, 35)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ОБСЕ назвала референдум о статусе Крыма незако...</td>\n",
       "      <td>644</td>\n",
       "      <td>[(ОБСЕ, 0, 3), (назвала, 5, 11), (референдум, ...</td>\n",
       "      <td>[(0, 3), (5, 11), (13, 22), (24, 24), (26, 32)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Египетского студента могут выслать из страны з...</td>\n",
       "      <td>645</td>\n",
       "      <td>[(Египетского, 0, 10), (студента, 12, 19), (мо...</td>\n",
       "      <td>[(0, 10), (12, 19), (21, 25), (27, 33), (35, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Геннадий Онищенко отправлен в отставку\\nГеннад...</td>\n",
       "      <td>646</td>\n",
       "      <td>[(Геннадий, 0, 7), (Онищенко, 9, 16), (отправл...</td>\n",
       "      <td>[(0, 7), (9, 16), (18, 26), (28, 28), (30, 37)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Племянник Алишера Усманова разбился в ДТП\\nВид...</td>\n",
       "      <td>647</td>\n",
       "      <td>[(Племянник, 0, 8), (Алишера, 10, 16), (Усмано...</td>\n",
       "      <td>[(0, 8), (10, 16), (18, 25), (27, 34), (36, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Владимир Булавин назначен на новую должность —...</td>\n",
       "      <td>648</td>\n",
       "      <td>[(Владимир, 0, 7), (Булавин, 9, 15), (назначен...</td>\n",
       "      <td>[(0, 7), (9, 15), (17, 24), (26, 27), (29, 33)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             senences   id  \\\n",
       "0   Владелец \"Бирмингема\" получил шесть лет тюрьмы...  584   \n",
       "1   Акция протеста на Майдане Независимости объявл...  585   \n",
       "2   Фольксваген может перейти под контроль Порше \\...  586   \n",
       "3   В Москве покажут фильмы Чарли Чаплина с живой ...  587   \n",
       "4   Чулпан Хаматова сыграет главную роль в фильме ...  588   \n",
       "..                                                ...  ...   \n",
       "60  ОБСЕ назвала референдум о статусе Крыма незако...  644   \n",
       "61  Египетского студента могут выслать из страны з...  645   \n",
       "62  Геннадий Онищенко отправлен в отставку\\nГеннад...  646   \n",
       "63  Племянник Алишера Усманова разбился в ДТП\\nВид...  647   \n",
       "64  Владимир Булавин назначен на новую должность —...  648   \n",
       "\n",
       "                                               tokens  \\\n",
       "0   [(Владелец, 0, 7), (``, 9, 9), (Бирмингема, 10...   \n",
       "1   [(Акция, 0, 4), (протеста, 6, 13), (на, 15, 16...   \n",
       "2   [(Фольксваген, 0, 10), (может, 12, 16), (перей...   \n",
       "3   [(В, 0, 0), (Москве, 2, 7), (покажут, 9, 15), ...   \n",
       "4   [(Чулпан, 0, 5), (Хаматова, 7, 14), (сыграет, ...   \n",
       "..                                                ...   \n",
       "60  [(ОБСЕ, 0, 3), (назвала, 5, 11), (референдум, ...   \n",
       "61  [(Египетского, 0, 10), (студента, 12, 19), (мо...   \n",
       "62  [(Геннадий, 0, 7), (Онищенко, 9, 16), (отправл...   \n",
       "63  [(Племянник, 0, 8), (Алишера, 10, 16), (Усмано...   \n",
       "64  [(Владимир, 0, 7), (Булавин, 9, 15), (назначен...   \n",
       "\n",
       "                                                spans  \n",
       "0   [(0, 7), (9, 9), (10, 19), (20, 20), (22, 28),...  \n",
       "1   [(0, 4), (6, 13), (15, 16), (18, 24), (26, 38)...  \n",
       "2   [(0, 10), (12, 16), (18, 24), (26, 28), (30, 3...  \n",
       "3   [(0, 0), (2, 7), (9, 15), (17, 22), (24, 28), ...  \n",
       "4   [(0, 5), (7, 14), (16, 22), (24, 30), (32, 35)...  \n",
       "..                                                ...  \n",
       "60  [(0, 3), (5, 11), (13, 22), (24, 24), (26, 32)...  \n",
       "61  [(0, 10), (12, 19), (21, 25), (27, 33), (35, 3...  \n",
       "62  [(0, 7), (9, 16), (18, 26), (28, 28), (30, 37)...  \n",
       "63  [(0, 8), (10, 16), (18, 25), (27, 34), (36, 36...  \n",
       "64  [(0, 7), (9, 15), (17, 24), (26, 27), (29, 33)...  \n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_json(DATASET_PATH / 'test.jsonl', lines=True)\n",
    "test['senences'] = test.senences.apply(lambda x: x.replace('«', '\\\"').replace('»', '\\\"'))\n",
    "test['tokens'] = test.senences.apply(lambda s: [(y, x[0], x[1] - 1) for y, x in zip(tokenizer.tokenize(s), tokenizer.span_tokenize(s))])\n",
    "test['spans'] =  test.senences.apply(lambda s: [(x, y - 1) for x, y in tokenizer.span_tokenize(s)])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     65.000000\n",
       "mean     259.461538\n",
       "std      124.075214\n",
       "min       95.000000\n",
       "25%      174.000000\n",
       "50%      255.000000\n",
       "75%      312.000000\n",
       "max      892.000000\n",
       "Name: tokens, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tokens.apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ners = []\n",
    "for _, row in test.iterrows():\n",
    "    tokens = row.tokens\n",
    "    spans = row.spans\n",
    "    for i in range(0, len(tokens), 32):\n",
    "        batch_tokens = tokens[i:i+32]\n",
    "        bert_tokens = list(map(bert_tokenizer.convert_tokens_to_ids, map(str, batch_tokens)))\n",
    "        outputs = model(input_ids=torch.tensor(bert_tokens, dtype=torch.long, device=device).unsqueeze(0))[1].predictions\n",
    "        tags = (torch.nn.functional.sigmoid(outputs) > 0.5).to(torch.long)\n",
    "        predicted_ners.append(convert_to_submit(tags.squeeze(dim=0), spans[i:i+32]))\n",
    "\n",
    "test['ners'] = pd.Series([[(x[1], x[2], x[0],) for x in y] for y in predicted_ners])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit = test.rename(columns={'senences': 'sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit = to_submit[['sentences', 'id', 'ners']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit.to_json('test.jsonl', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
